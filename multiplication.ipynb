{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656bcc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from tqdm import tqdm\n",
    "DEBUG = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50c36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_size = 10000, dim = 1, bound = 100, rand_dist = \"uniform\"):\n",
    "    data_list = []\n",
    "    if rand_dist == \"uniform\":\n",
    "        rand_func = pt.rand\n",
    "    elif rand_dist == \"normal\":\n",
    "        rand_func = pt.randn\n",
    "    else:\n",
    "        raise NotImplementedError(\"Must choose from uniform or normal distribution.\")\n",
    "    \n",
    "    for _ in range(data_size): \n",
    "        x = rand_func(dim) * bound\n",
    "        y = rand_func(dim) * bound\n",
    "        z = (x * y).unsqueeze(0)\n",
    "        x = pt.concat((x, y), dim = 0).unsqueeze(0)\n",
    "        data_list.append((x, z))\n",
    "        \n",
    "            \n",
    "    if DEBUG:\n",
    "        print(f\"generated {data_size} pairs\")\n",
    "        print(\"Example data:\")\n",
    "        print(f\"    x = {x[0, : dim]}\")\n",
    "        print(f\"    y = {x[0, dim: ]}\")\n",
    "        print(f\"    z =  x * y = {z}\")\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85fe2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @classmethod\n",
    "    def collate_fn(cls, batch):\n",
    "        x, z = zip(*batch)\n",
    "        x = pt.concat(x, dim=0)\n",
    "        z = pt.concat(z, dim=0)\n",
    "        return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.activation_func = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.input_layer(x)\n",
    "        h = self.activation_func(h)\n",
    "        output = self.output_layer(h)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_num, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_num = hidden_num\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(hidden_num)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.activation_func = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        h = self.input_layer(x)\n",
    "        h = self.activation_func(h)\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "            h = self.activation_func(h)\n",
    "        output = self.output_layer(h)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93212190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "epochs = 1000\n",
    "device = pt.device(\"cuda\")\n",
    "train_dataset = MultDataset(generate_data(dim=dim, bound=1))\n",
    "test_dataset = MultDataset(generate_data(1000, dim=dim, bound=10))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=MultDataset.collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, collate_fn=MultDataset.collate_fn)\n",
    "#model = LP(2*dim, 30*dim, dim).to(device)\n",
    "model = MLP(2*dim, 30*dim, 3, dim).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=5e-4)# SGD(model.parameters(), lr = 1e-2)\n",
    "print(len(test_dataset))\n",
    "\n",
    "normalized_input = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x, z in tqdm(train_dataloader, desc=f'epoch {epoch}'):\n",
    "        x = x.to(device)\n",
    "        z = z.to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x).squeeze()\n",
    "        loss = loss_fn(pred, z.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc = 0\n",
    "    res = 0\n",
    "    model.eval()\n",
    "    for x, z in tqdm(test_dataloader):\n",
    "        x = x.to(device)\n",
    "        z = z.to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x).squeeze()\n",
    "        diff = (z - pred) ** 2\n",
    "        res += diff.sum()\n",
    "        acc += (diff < 1).sum()\n",
    "    if epochs < 200 or (epoch % 20 == 0):\n",
    "        print(f'acc {acc/1000}')\n",
    "        print(f'res {res/1000}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
